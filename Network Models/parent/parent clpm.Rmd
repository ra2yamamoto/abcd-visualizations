# Cross-lagged Panel Modeling of Parent Variables

```{r}
################################################################
# Cross-Lagged Panel Modeling of Parent Variables (ABCD Data)
#
# Overview:
# This script estimates longitudinal networks spanning parent 
# symptom domains across three assessment waves (baseline, 2y FU, 4y FU).
# Using LASSO regression with cross-validation, it models both 
# autoregressive and cross-lagged influences, computes network centrality,
# and evaluates stability with bootstrap methods.
#
# Main Steps:
# 1. Data Preparation
#    • Load extracted long-format ABCD data
#    • Reshape to wide format for 3 timepoints (0,2,4)
#    • Restrict to subjects with complete data (no NA across all variables at each included wave)
#
# 2. Model Fitting
#    • Fit LASSO regressions for each transition (0→2, 2→4)
#    • Extract optimal λ values and adjacency matrices of effects
#
# 3. Network Analysis
#    • Build directed weighted networks
#    • Compute centrality metrics (In/Out-Strength, Betweenness, Closeness)
#    • Export edge weights and centrality tables to CSV
#
# 4. Visualization
#    • Plot centrality trajectories across waves
#    • Visualize networks with spring layouts
#
# 5. Robustness / Bootstrapping
#    • Nonparametric bootstrap (nBoots=1000)
#    • Case-dropping bootstrap (nBoots=2500)
#    • Assess stability of edges and centrality estimates
#    • Save results to boot_data/ and plots to boot_photos/
#
# Parallelization:
# • Uses doParallel backend (4 workers) to speed up cross-validation
#
# Outputs:
# • Centrality plots and network visualizations (PNG)
# • Edge weights and centrality metrics (CSV)
# • Bootstrap stability results (RData + PNG)
#
################################################################
```

```{r}
library(glmnet)
library(qgraph)
library(dplyr)
library(tidyr)
library(bootnet)
library(doParallel)
registerDoParallel(4)
```

```{r}
# Load necessary libraries
library(readr)  # for read_csv

# Load the dataset
df <- read_csv("CLEAN_ABCD_5.1_panel_20250321.csv") # load extracted data

current_output_files <- list(
    network_plot = "CLPN_network_transitions_balanced_4tp.png",
    centrality_plot = "centrality_plots_4tp.png",
    edge_values = "network_edge_values_4tp.csv",
    centrality_metrics = "network_centrality_metrics_4tp.csv",
    summary_stats = "network_summary_statistics_4tp.csv"
  )
```

```{r}
set.seed(42)
```

```{r}
# Function to extract data for LASSO (with missing value removal)
extract_lasso_data <- function(data_long, variable_roots, id_var = "subject", time_var = "time") {
  # Step 1: Keep only relevant variables + id + time
  needed_vars <- c(id_var, time_var, variable_roots)
  data_sub <- data_long[, intersect(colnames(data_long), needed_vars)]
  
  # Step 2: Filter to timepoints 0, 2, 4
  data_sub <- data_sub %>%
    filter(!!sym(time_var) %in% c(0, 2, 4))
  
  # Step 3: Pivot wider so each variable_timepoint is its own column
  data_wide <- data_sub %>%
    pivot_wider(
      id_cols = !!sym(id_var),
      names_from = time_var,
      values_from = all_of(variable_roots),
      names_sep = "_"
    )
  
  # Step 4: Drop subjects with missing values in the required columns
  # We need to create the required columns list based on variable_roots and timepoints 0, 2, 4
  required_cols <- c()
  for (t in c(0, 2, 4)) {
    required_cols <- c(required_cols, paste(variable_roots, t, sep = "_"))
  }
  
  # Drop rows (subjects) with missing data in the required columns
  data_wide <- data_wide %>%
    drop_na(all_of(required_cols))
  
  # Return the cleaned wide-format data
  return(data_wide)
}

```

```{r}
library(glmnet)

# For each transition (t -> t+1), fit k separate CV-LASSO models (one per outcome variable at t+1).
# Each model uses all k variables at time t as predictors. Coefs populate the adjacency matrix column-wise. 
run_lasso_transition <- function(data_wide, variable_roots, verbose = FALSE) {
  timepoints <- c(0, 2, 4)
  k <- length(variable_roots)
  
  AdjMatList <- vector("list", length(timepoints) - 1)
  LambdaList <- vector("list", length(timepoints) - 1)
  
  for (t in 1:(length(timepoints) - 1)) {
    if (verbose) cat(sprintf("\nTransition %d -> %d\n", timepoints[t], timepoints[t+1]))
    
    predictor_vars <- paste0(variable_roots, "_", timepoints[t])
    outcome_vars   <- paste0(variable_roots, "_", timepoints[t+1])
    
    predictors <- as.matrix(data_wide[, predictor_vars])
    
    adjMat <- matrix(0, k, k)
    colnames(adjMat) <- variable_roots
    rownames(adjMat) <- variable_roots
    
    lambdaVec <- rep(NA, k)
    
    for (i in 1:k) {
      outcome <- as.numeric(unlist(data_wide[, outcome_vars[i]]))
      
      if (all(is.finite(outcome))) {
        fit <- cv.glmnet(
          x = predictors,
          y = outcome,
          family = "gaussian",
          alpha = 1,
          standardize = TRUE,
          parallel=TRUE
        )
        lambdaVec[i] <- fit$lambda.min
        adjMat[, i] <- as.numeric(coef(fit, s = fit$lambda.min)[-1])
      } else {
        warning(sprintf("Skipping outcome %s due to non-finite values.", outcome_vars[i]))
      }
    }
    
    # adjMat[, i] stores predictors -> outcome i for the next wave.
    
    AdjMatList[[t]] <- adjMat
    LambdaList[[t]] <- lambdaVec
  }
  
  return(list(B = AdjMatList, lambdas = LambdaList))
}
```

```{r}
# 1. List your variable roots (no timepoint suffixes)
variable_roots <- c('parent_depress_D_p', 'parent_anxdisord_D_p', 'parent_external_D_p', 'parent_adhd_D_p', 'parent_somatic_problems_D_p')

# 2. Extract the wide data
data_wide <- extract_lasso_data(df, variable_roots)
```

```{r}
# 3. Run LASSO transitions
model_fit <- run_lasso_transition(data_wide, variable_roots)
```

# Export edge values

```{r}
vars <- variable_roots
```

```{r edge_values}

edge_values_list <- list()

for(t in 1:length(model_fit$B)) {
  adj_mat <- model_fit$B[[t]]
  
  edges <- expand.grid(
    From = vars,
    To = vars,
    stringsAsFactors = FALSE
  )
  
  edges$Weight <- as.vector(adj_mat)
  edges$Transition <- paste("Wave", (t - 1) * 2, "to", t*2)
  
  edge_values_list[[t]] <- edges
}

all_edge_values <- do.call(rbind, edge_values_list)
write.csv(all_edge_values, current_output_files$edge_values, row.names = FALSE)
```

# Centrality metrics functions

```{r centrality_metrics}
getCentralityMetrics <- function(adjMatList) {
  centrality_list <- list()
  
  for(t in 1:length(adjMatList)) {
    adj_mat <- adjMatList[[t]]
    
    # Calculate InStrength and OutStrength manually
    in_strength <- colSums(abs(adj_mat))
    out_strength <- rowSums(abs(adj_mat))
    
    # Create qgraph object for other centrality measures
    g <- qgraph(adj_mat, directed = TRUE, weighted = TRUE)
    cent <- centrality(g)
    
    # Create data frame with metrics
    centrality_df <- data.frame(
      Wave = rep(paste("Wave", (t - 1) * 2, "to", t*2), length(vars)),
      Node = vars,
      InStrength = in_strength,
      OutStrength = out_strength,
      Betweenness = cent$Betweenness,
      Closeness = cent$Closeness,
      stringsAsFactors = FALSE
    )
    
    centrality_list[[t]] <- centrality_df
  }
  
  all_centrality <- do.call(rbind, centrality_list)
  write.csv(all_centrality, current_output_files$centrality_metrics, row.names = FALSE)
  
  return(centrality_list)
}

# Calculate centrality metrics
centrality_metrics <- getCentralityMetrics(model_fit$B)
```

# Create Centrality and Network Plots

```{r}
B_list <- model_fit$B

# Define colors for nodes
node_colors <- c("#00008B", "#950606", "#06402B", "#BA8E23", "#6e352a")

# Define groups
groups <- list(
  "parent_depress_D_p" = 1, 
  "parent_anxdisord_D_p" = 2, 
  "parent_external_D_p" = 3, 
  "parent_adhd_D_p" = 4, 
  "parent_somatic_problems_D_p" = 5
)

# Plot centrality metrics to file
png("centrality_plot.png", width = 12, height = 8, res = 600, units = "in")

par(mfrow = c(2,2), mar = c(4,4,2,1))
all_metrics <- do.call(rbind, centrality_metrics)
metric_names <- c("InStrength", "OutStrength", "Betweenness", "Closeness")

# Plot each centrality metric across transitions
for(metric in metric_names) {
  # Reshape data: create a matrix with rows = nodes and columns = transitions
  metric_data <- matrix(0, nrow = length(vars), ncol = length(centrality_metrics))
  for(t in 1:length(centrality_metrics)) {
    metric_data[,t] <- centrality_metrics[[t]][,metric]
  }
  rownames(metric_data) <- vars
  
  matplot(t(metric_data), type = "b", pch = 1:length(vars),
          main = metric, xlab = "Wave", ylab = "Centrality Value",
          col = node_colors)
}

dev.off()

# Save the legend as a separate image
png("centrality_legend_plot.png", width = 6, height = 4, res = 600, units = "in")
# Plot only the legend
plot.new()
legend("center", legend = vars, col = node_colors, pch = 1:length(vars), 
       cex = 1, horiz = FALSE, bty = "n")
dev.off()  # Close the PNG device

# Calculate maximum absolute edge values for scaling
max_edge <- max(unlist(lapply(B_list, function(x) max(abs(x)))))
max_cross <- max(unlist(lapply(B_list, function(x) {
  diag(x) <- 0  # Zero out diagonal for cross-lagged effects
  return(max(abs(x)))
})))

# Generate initial spring layout from the first transition
initial_graph <- qgraph(B_list[[1]], 
                        layout = "spring",
                        repulsion = 1.2,
                        labels = vars)
spring_layout <- initial_graph$layout

# Determine the number of transitions
n_transitions <- length(B_list)

# Create network plots for each transition with a dynamic width based on the number of transitions
plot_width <- 10 * n_transitions  # 8 inches per transition
png("network_plot.png", width = plot_width, height = 8, res = 600, units = "in")

layout(matrix(1:n_transitions, 1, n_transitions), widths = rep(1, n_transitions))
# par(mar = rep(2, 4))
AUTO_EDGE_MULTIPLIER <- 2
CROSS_EDGE_MULTIPLIER <- 8

par(mar = c(5, 5, 5, 5))

for(t in 1:length(B_list)) {
  adj_mat <- B_list[[t]]
  edge_colors <- matrix(NA, nrow = nrow(adj_mat), ncol = ncol(adj_mat))
  edge_weights <- matrix(0, nrow = nrow(adj_mat), ncol = ncol(adj_mat))
  
  for(i in 1:nrow(adj_mat)) {
    for(j in 1:ncol(adj_mat)) {
      if(i == j) {  # Autoregressive effects
        alpha_val <- min(1, (abs(adj_mat[i,j]) / max_edge) * 1.5 + 0.2)
        edge_weights[i,j] <- abs(adj_mat[i,j]) * AUTO_EDGE_MULTIPLIER
      } else {      # Cross-lagged effects
        alpha_val <- min(1, (abs(adj_mat[i,j]) / max_cross) * 2.5 + 0.2)
        edge_weights[i,j] <- abs(adj_mat[i,j]) * CROSS_EDGE_MULTIPLIER
      }
      if(adj_mat[i,j] > 0) {
        edge_colors[i,j] <- adjustcolor("#377EB8", alpha.f = alpha_val)  
      } else {
        edge_colors[i,j] <- adjustcolor("#E41A1C", alpha.f = alpha_val)  
      }
    }
  }
  
  # Set a minimum edge threshold for plotting clarity.
  # edge_weights[edge_weights > 0 & edge_weights < 0.15] <- 0.15
  
  qgraph(adj_mat,
         layout = spring_layout,
         groups = groups,
         labels = vars,
         color = node_colors,
         edge.color = edge_colors,
         edge.width = edge_weights,
         edge.labels = FALSE,  
         label.cex = 1.4,     
         label.scale = TRUE,
         node.width = 2.5,    
         node.height = 2.5,   
         directed = TRUE,
         arrows = TRUE,
         asize = 3,          
         edge.length = 1.4,  
         maximum = max_edge * 0.4,
         minimum = 0.001,    
         cut = 0.001,       
         fade = FALSE,
         title = paste("Wave", (t - 1) * 2, "to", t*2),
         title.cex = 1.5,
         vsize = 3)
}

dev.off()
```

# Bootstrapping with bootnet

```{r}
# Wrap getAdjMatList call so bootnet can re‐estimate network on resampled data
getMat_i = function (i, data) {
  function (data) {
    run_lasso_transition(data, variable_roots)$B[[i]]
  }
}
```

# Non-parametric Bootstrap

```{r}
for (i in 1:2) {
  Network <- estimateNetwork(data_wide, directed=TRUE, fun=getMat_i(i), labels=variable_roots)
  
  boot <- bootnet(Network, nBoots = 1000, statistics=c("edge", "strength", "outStrength", "inStrength", "betweenness", "closeness"))
  
  save(boot, file = paste("boot_data/", i, "_normal_boot.RData", sep=""))
  
  png(paste("boot_photos/normal_boot_", i, ".png", sep = ""), width = 6, height = 4, res = 600, units = "in")
  p <- plot(boot, order = "sample")
  print(p)
  dev.off()  # Close the PNG device
}
```

# Case-Dropping Bootstrap

```{r}
for (i in 1:2) {
  Network <- estimateNetwork(data_wide, directed=TRUE, fun=getMat_i(i), labels=variable_roots)
  
  boot <- bootnet(Network, nBoots = 2500, type="case", statistics=c("edge", "strength", "outStrength", "inStrength", "betweenness", "closeness"))
  
  save(boot, file = paste("boot_data/", i, "_case_boot.RData", sep=""))
  
  png(paste("boot_photos/case_boot_", i, ".png", sep = ""), width = 6, height = 4, res = 600, units = "in")
  p <- plot(boot, statistics=c("outStrength", "inStrength"))
  print(p)
  dev.off()  # Close the PNG device
}
```
